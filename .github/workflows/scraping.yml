name: Daily Scraping and CSV Update

on:
  schedule:
    - cron: '0 3 * * *'  # 毎日3時に実行（UTC時間）
  push:
    branches:
      - main

jobs:
  scrape_and_update_csv:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Scraping Script
      run: |
        python scrape.py

    - name: Run Cleanup Script
      run: |
        python add_unique_data.py

    - name: Transfer CSV to Server
      env:
        SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}  # GitHub Secretsに保存したSSHキー
      run: |
        mkdir -p ~/.ssh
        echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        ssh-keyscan -H your_server_ip >> ~/.ssh/known_hosts
        scp data.csv your_user@your_server_ip:/path/to/your/folder
